---
title: "Anthropic Will Now Train Claude on Your Chats, Here's How to Opt Out"
date: 2025-08-28T17:46:43+08:00
categories: ["tech"]
tags: ["Anthropic"]
summary: "Anthropic announced today that it is changing its Consumer Terms and Privacy Policy, with plans to train its AI chatbot Claude with user data. New users will be able to opt out at signup. Existing use"
source_url: "https://www.macrumors.com/2025/08/28/anthropic-claude-chat-training/"
---

Anthropic announced today that it is changing its Consumer Terms and Privacy Policy, with plans to train its AI chatbot Claude with user data. New users will be able to opt out at signup. Existing users will receive a popup that allows them to opt out of Anthropic using their data for AI training purposes. The popup is labeled "Updates to Consumer Terms and Policies," and when it shows up, unchecking the "You can help improve Claude" toggle will disallow the use of chats. Choosing to accept the policy now will allow all new or resumed chats to be used by Anthropic. Users will need to opt in or opt out by September 28, 2025, to continue using Claude. Opting out can also be done by going to Claude's Settings, selecting the Privacy option, and toggling off "Help improve Claude." Anthropic says that the new training policy will allow it to deliver "even more capable, useful AI models" and strengthen safeguards against harmful usage like scams and abuse. The updated terms apply to all users...

---

*来源: [原文链接](https://www.macrumors.com/2025/08/28/anthropic-claude-chat-training/)*
