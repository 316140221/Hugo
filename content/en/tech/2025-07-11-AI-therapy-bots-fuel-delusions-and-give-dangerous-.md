---
title: "AI therapy bots fuel delusions and give dangerous advice, Stanford study finds"
date: 2025-07-11T22:01:10+08:00
categories: ["tech"]
tags: ["AI", "Biz & IT", "Science", "7cups", "AI behavior", "AI ethics", "AI regulation", "AI safety", "AI sycophancy", "Character.AI", "ChatGPT", "clinical psychology", "delusions", "Jared Moore", "machine learning", "mental health", "Nick Haber", "openai", "Stanford University", "stigma", "suicidal ideation", "therapy"]
summary: "Popular chatbots serve as poor replacements for human therapists, but study authors call for nuance."
source_url: "https://arstechnica.com/ai/2025/07/ai-therapy-bots-fuel-delusions-and-give-dangerous-advice-stanford-study-finds/"
---

Popular chatbots serve as poor replacements for human therapists, but study authors call for nuance.

---

*来源: [原文链接](https://arstechnica.com/ai/2025/07/ai-therapy-bots-fuel-delusions-and-give-dangerous-advice-stanford-study-finds/)*
