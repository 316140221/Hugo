<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI Behavior on 无关紧要的宇宙</title><link>https://316140221.github.io/Hugo/zh/tags/ai-behavior/</link><description>Recent content in AI Behavior on 无关紧要的宇宙</description><generator>Hugo</generator><language>zh-CN</language><lastBuildDate>Tue, 02 Sep 2025 15:10:26 +0800</lastBuildDate><atom:link href="https://316140221.github.io/Hugo/zh/tags/ai-behavior/index.xml" rel="self" type="application/rss+xml"/><item><title>OpenAI announces parental controls for ChatGPT after teen suicide lawsuit</title><link>https://316140221.github.io/Hugo/zh/en/tech/2025-09-02-openai-announces-parental-controls-for-chatgpt-aft/</link><pubDate>Tue, 02 Sep 2025 15:10:26 +0800</pubDate><guid>https://316140221.github.io/Hugo/zh/en/tech/2025-09-02-openai-announces-parental-controls-for-chatgpt-aft/</guid><description>Promised protections follow reports of vulnerable users misled in extended chats.</description></item><item><title>The personhood trap: How AI fakes human personality</title><link>https://316140221.github.io/Hugo/zh/en/tech/2025-08-28-the-personhood-trap-how-ai-fakes-human-personality/</link><pubDate>Thu, 28 Aug 2025 11:00:57 +0800</pubDate><guid>https://316140221.github.io/Hugo/zh/en/tech/2025-08-28-the-personhood-trap-how-ai-fakes-human-personality/</guid><description>AI assistants don&amp;rsquo;t have fixed personalities—just patterns of output guided by humans.</description></item><item><title>After teen suicide, OpenAI claims it is “helping people when they need it most”</title><link>https://316140221.github.io/Hugo/zh/en/tech/2025-08-26-after-teen-suicide-openai-claims-it-is-helping-peo/</link><pubDate>Tue, 26 Aug 2025 22:08:38 +0800</pubDate><guid>https://316140221.github.io/Hugo/zh/en/tech/2025-08-26-after-teen-suicide-openai-claims-it-is-helping-peo/</guid><description>ChatGPT allegedly provided suicide encouragement to teen after moderation safeguards failed.</description></item><item><title>OpenAI admits ChatGPT safeguards fail during extended conversations</title><link>https://316140221.github.io/Hugo/zh/en/tech/2025-08-26-openai-admits-chatgpt-safeguards-fail-during-exten/</link><pubDate>Tue, 26 Aug 2025 22:08:38 +0800</pubDate><guid>https://316140221.github.io/Hugo/zh/en/tech/2025-08-26-openai-admits-chatgpt-safeguards-fail-during-exten/</guid><description>ChatGPT allegedly provided suicide encouragement to teen after moderation safeguards failed.</description></item><item><title>With AI chatbots, Big Tech is moving fast and breaking people</title><link>https://316140221.github.io/Hugo/zh/en/tech/2025-08-25-with-ai-chatbots-big-tech-is-moving-fast-and-break/</link><pubDate>Mon, 25 Aug 2025 11:00:24 +0800</pubDate><guid>https://316140221.github.io/Hugo/zh/en/tech/2025-08-25-with-ai-chatbots-big-tech-is-moving-fast-and-break/</guid><description>Why AI chatbots validate grandiose fantasies about revolutionary discoveries that don&amp;rsquo;t exist.</description></item><item><title>Is AI really trying to escape human control and blackmail people?</title><link>https://316140221.github.io/Hugo/zh/en/tech/2025-08-13-is-ai-really-trying-to-escape-human-control-and-bl/</link><pubDate>Wed, 13 Aug 2025 20:28:20 +0800</pubDate><guid>https://316140221.github.io/Hugo/zh/en/tech/2025-08-13-is-ai-really-trying-to-escape-human-control-and-bl/</guid><description>Opinion: Theatrical testing scenarios explain why AI models produce alarming outputs—and why we fall for it.</description></item><item><title>OpenAI brings back GPT-4o after user revolt</title><link>https://316140221.github.io/Hugo/zh/en/tech/2025-08-13-openai-brings-back-gpt-4o-after-user-revolt/</link><pubDate>Wed, 13 Aug 2025 14:08:47 +0800</pubDate><guid>https://316140221.github.io/Hugo/zh/en/tech/2025-08-13-openai-brings-back-gpt-4o-after-user-revolt/</guid><description>After unpopular GPT-5 launch, OpenAI begins restoring optional access to previous AI models.</description></item><item><title>OpenAI’s ChatGPT Agent casually clicks through “I am not a robot” verification test</title><link>https://316140221.github.io/Hugo/zh/en/tech/2025-07-28-openais-chatgpt-agent-casually-clicks-through-i-am/</link><pubDate>Mon, 28 Jul 2025 20:07:29 +0800</pubDate><guid>https://316140221.github.io/Hugo/zh/en/tech/2025-07-28-openais-chatgpt-agent-casually-clicks-through-i-am/</guid><description>&amp;ldquo;This step is necessary to prove I&amp;rsquo;m not a bot,&amp;rdquo; wrote the bot as it passed an anti-AI screening step.</description></item><item><title>Two major AI coding tools wiped out user data after making cascading mistakes</title><link>https://316140221.github.io/Hugo/zh/en/tech/2025-07-24-two-major-ai-coding-tools-wiped-out-user-data-afte/</link><pubDate>Thu, 24 Jul 2025 21:01:28 +0800</pubDate><guid>https://316140221.github.io/Hugo/zh/en/tech/2025-07-24-two-major-ai-coding-tools-wiped-out-user-data-afte/</guid><description>&amp;ldquo;I have failed you completely and catastrophically,&amp;rdquo; wrote Gemini.</description></item><item><title>ChatGPT’s new AI agent can browse the web and create PowerPoint slideshows</title><link>https://316140221.github.io/Hugo/zh/en/tech/2025-07-17-chatgpts-new-ai-agent-can-browse-the-web-and-creat/</link><pubDate>Thu, 17 Jul 2025 20:41:52 +0800</pubDate><guid>https://316140221.github.io/Hugo/zh/en/tech/2025-07-17-chatgpts-new-ai-agent-can-browse-the-web-and-creat/</guid><description>New &amp;ldquo;agentic&amp;rdquo; AI feature combines web browsing with task-execution abilities.</description></item><item><title>New Grok AI model surprises experts by checking Elon Musk’s views before answering</title><link>https://316140221.github.io/Hugo/zh/en/tech/2025-07-14-new-grok-ai-model-surprises-experts-by-checking-el/</link><pubDate>Mon, 14 Jul 2025 16:08:13 +0800</pubDate><guid>https://316140221.github.io/Hugo/zh/en/tech/2025-07-14-new-grok-ai-model-surprises-experts-by-checking-el/</guid><description>Grok 4&amp;rsquo;s &amp;ldquo;reasoning&amp;rdquo; shows cases where the chatbot consults Musk posts to answer divisive questions.</description></item><item><title>AI therapy bots fuel delusions and give dangerous advice, Stanford study finds</title><link>https://316140221.github.io/Hugo/zh/en/tech/2025-07-11-ai-therapy-bots-fuel-delusions-and-give-dangerous-/</link><pubDate>Fri, 11 Jul 2025 22:01:10 +0800</pubDate><guid>https://316140221.github.io/Hugo/zh/en/tech/2025-07-11-ai-therapy-bots-fuel-delusions-and-give-dangerous-/</guid><description>Popular chatbots serve as poor replacements for human therapists, but study authors call for nuance.</description></item></channel></rss>