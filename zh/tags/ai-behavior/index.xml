<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI Behavior on 无关紧要的宇宙</title><link>https://316140221.github.io/Hugo/zh/tags/ai-behavior/</link><description>Recent content in AI Behavior on 无关紧要的宇宙</description><generator>Hugo</generator><language>zh-CN</language><lastBuildDate>Fri, 11 Jul 2025 22:01:10 +0800</lastBuildDate><atom:link href="https://316140221.github.io/Hugo/zh/tags/ai-behavior/index.xml" rel="self" type="application/rss+xml"/><item><title>AI therapy bots fuel delusions and give dangerous advice, Stanford study finds</title><link>https://316140221.github.io/Hugo/zh/en/tech/2025-07-11-ai-therapy-bots-fuel-delusions-and-give-dangerous-/</link><pubDate>Fri, 11 Jul 2025 22:01:10 +0800</pubDate><guid>https://316140221.github.io/Hugo/zh/en/tech/2025-07-11-ai-therapy-bots-fuel-delusions-and-give-dangerous-/</guid><description>Popular chatbots serve as poor replacements for human therapists, but study authors call for nuance.</description></item></channel></rss>