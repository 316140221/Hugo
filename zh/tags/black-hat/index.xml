<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Black Hat on 无关紧要的宇宙</title><link>https://316140221.github.io/Hugo/zh/tags/black-hat/</link><description>Recent content in Black Hat on 无关紧要的宇宙</description><generator>Hugo</generator><language>zh-CN</language><lastBuildDate>Wed, 06 Aug 2025 23:30:00 +0800</lastBuildDate><atom:link href="https://316140221.github.io/Hugo/zh/tags/black-hat/index.xml" rel="self" type="application/rss+xml"/><item><title>A Single Poisoned Document Could Leak ‘Secret’ Data Via ChatGPT</title><link>https://316140221.github.io/Hugo/zh/en/tech/2025-08-06-a-single-poisoned-document-could-leak-secret-data-/</link><pubDate>Wed, 06 Aug 2025 23:30:00 +0800</pubDate><guid>https://316140221.github.io/Hugo/zh/en/tech/2025-08-06-a-single-poisoned-document-could-leak-secret-data-/</guid><description>Security researchers found a weakness in OpenAI’s Connectors, which let you hook up ChatGPT to other services, that allowed them to extract data from a Google Drive without any user interaction.</description></item><item><title>A Single Poisoned Document Could Leak ‘Secret’ Data Via ChatGPT</title><link>https://316140221.github.io/Hugo/zh/zh/tech/2025-08-06-a-single-poisoned-document-could-leak-secret-data-/</link><pubDate>Wed, 06 Aug 2025 23:30:00 +0800</pubDate><guid>https://316140221.github.io/Hugo/zh/zh/tech/2025-08-06-a-single-poisoned-document-could-leak-secret-data-/</guid><description>Security researchers found a weakness in OpenAI’s Connectors, which let you hook up ChatGPT to other services, that allowed them to extract data from a Google Drive without any user interaction.</description></item><item><title>Hackers Hijacked Google’s Gemini AI With a Poisoned Calendar Invite to Take Over a Smart Home</title><link>https://316140221.github.io/Hugo/zh/en/tech/2025-08-06-hackers-hijacked-googles-gemini-ai-with-a-poisoned/</link><pubDate>Wed, 06 Aug 2025 13:00:00 +0800</pubDate><guid>https://316140221.github.io/Hugo/zh/en/tech/2025-08-06-hackers-hijacked-googles-gemini-ai-with-a-poisoned/</guid><description>For likely the first time ever, security researchers have shown how AI can be hacked to create real world havoc, allowing them to turn off lights, open smart shutters, and more.</description></item><item><title>Hackers Hijacked Google’s Gemini AI With a Poisoned Calendar Invite to Take Over a Smart Home</title><link>https://316140221.github.io/Hugo/zh/zh/tech/2025-08-06-hackers-hijacked-googles-gemini-ai-with-a-poisoned/</link><pubDate>Wed, 06 Aug 2025 13:00:00 +0800</pubDate><guid>https://316140221.github.io/Hugo/zh/zh/tech/2025-08-06-hackers-hijacked-googles-gemini-ai-with-a-poisoned/</guid><description>For likely the first time ever, security researchers have shown how AI can be hacked to create real world havoc, allowing them to turn off lights, open smart shutters, and more.</description></item></channel></rss>