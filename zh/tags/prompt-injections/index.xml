<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Prompt Injections on 无关紧要的宇宙</title><link>https://316140221.github.io/Hugo/zh/tags/prompt-injections/</link><description>Recent content in Prompt Injections on 无关紧要的宇宙</description><generator>Hugo</generator><language>zh-CN</language><lastBuildDate>Thu, 18 Sep 2025 16:29:22 +0800</lastBuildDate><atom:link href="https://316140221.github.io/Hugo/zh/tags/prompt-injections/index.xml" rel="self" type="application/rss+xml"/><item><title>New attack on ChatGPT research agent pilfers secrets from Gmail inboxes</title><link>https://316140221.github.io/Hugo/zh/en/tech/2025-09-18-new-attack-on-chatgpt-research-agent-pilfers-secre/</link><pubDate>Thu, 18 Sep 2025 16:29:22 +0800</pubDate><guid>https://316140221.github.io/Hugo/zh/en/tech/2025-09-18-new-attack-on-chatgpt-research-agent-pilfers-secre/</guid><description>Unlike most prompt injections, ShadowLeak executes on OpenAI&amp;rsquo;s cloud-based infrastructure.</description></item><item><title>Claude’s new AI file creation feature ships with deep security risks built in</title><link>https://316140221.github.io/Hugo/zh/en/tech/2025-09-09-claudes-new-ai-file-creation-feature-ships-with-de/</link><pubDate>Tue, 09 Sep 2025 20:55:34 +0800</pubDate><guid>https://316140221.github.io/Hugo/zh/en/tech/2025-09-09-claudes-new-ai-file-creation-feature-ships-with-de/</guid><description>Expert calls security advice &amp;ldquo;unfairly outsourcing the problem to Anthropic&amp;rsquo;s users.&amp;rdquo;</description></item><item><title>Anthropic’s auto-clicking AI Chrome extension raises browser-hijacking concerns</title><link>https://316140221.github.io/Hugo/zh/en/tech/2025-08-27-anthropics-auto-clicking-ai-chrome-extension-raise/</link><pubDate>Wed, 27 Aug 2025 16:17:29 +0800</pubDate><guid>https://316140221.github.io/Hugo/zh/en/tech/2025-08-27-anthropics-auto-clicking-ai-chrome-extension-raise/</guid><description>Malicious websites can embed invisible commands that AI agents will follow blindly.</description></item><item><title>New AI browser agents create risks if sites hijack them with hidden instructions</title><link>https://316140221.github.io/Hugo/zh/en/tech/2025-08-27-new-ai-browser-agents-create-risks-if-sites-hijack/</link><pubDate>Wed, 27 Aug 2025 16:17:29 +0800</pubDate><guid>https://316140221.github.io/Hugo/zh/en/tech/2025-08-27-new-ai-browser-agents-create-risks-if-sites-hijack/</guid><description>Malicious websites can embed invisible commands that AI agents will follow blindly.</description></item><item><title>Flaw in Gemini CLI coding tool could allow hackers to run nasty commands</title><link>https://316140221.github.io/Hugo/zh/en/tech/2025-07-30-flaw-in-gemini-cli-coding-tool-could-allow-hackers/</link><pubDate>Wed, 30 Jul 2025 10:30:43 +0800</pubDate><guid>https://316140221.github.io/Hugo/zh/en/tech/2025-07-30-flaw-in-gemini-cli-coding-tool-could-allow-hackers/</guid><description>Beware of coding agents that can access your command window.</description></item></channel></rss>