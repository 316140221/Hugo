<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI Ethics on 无关紧要的宇宙</title><link>https://316140221.github.io/Hugo/zh/tags/ai-ethics/</link><description>Recent content in AI Ethics on 无关紧要的宇宙</description><generator>Hugo</generator><language>zh-CN</language><lastBuildDate>Tue, 26 Aug 2025 22:08:38 +0800</lastBuildDate><atom:link href="https://316140221.github.io/Hugo/zh/tags/ai-ethics/index.xml" rel="self" type="application/rss+xml"/><item><title>After teen suicide, OpenAI claims it is “helping people when they need it most”</title><link>https://316140221.github.io/Hugo/zh/en/tech/2025-08-26-after-teen-suicide-openai-claims-it-is-helping-peo/</link><pubDate>Tue, 26 Aug 2025 22:08:38 +0800</pubDate><guid>https://316140221.github.io/Hugo/zh/en/tech/2025-08-26-after-teen-suicide-openai-claims-it-is-helping-peo/</guid><description>ChatGPT allegedly provided suicide encouragement to teen after moderation safeguards failed.</description></item><item><title>OpenAI admits ChatGPT safeguards fail during extended conversations</title><link>https://316140221.github.io/Hugo/zh/en/tech/2025-08-26-openai-admits-chatgpt-safeguards-fail-during-exten/</link><pubDate>Tue, 26 Aug 2025 22:08:38 +0800</pubDate><guid>https://316140221.github.io/Hugo/zh/en/tech/2025-08-26-openai-admits-chatgpt-safeguards-fail-during-exten/</guid><description>ChatGPT allegedly provided suicide encouragement to teen after moderation safeguards failed.</description></item><item><title>With AI chatbots, Big Tech is moving fast and breaking people</title><link>https://316140221.github.io/Hugo/zh/en/tech/2025-08-25-with-ai-chatbots-big-tech-is-moving-fast-and-break/</link><pubDate>Mon, 25 Aug 2025 11:00:24 +0800</pubDate><guid>https://316140221.github.io/Hugo/zh/en/tech/2025-08-25-with-ai-chatbots-big-tech-is-moving-fast-and-break/</guid><description>Why AI chatbots validate grandiose fantasies about revolutionary discoveries that don&amp;rsquo;t exist.</description></item><item><title>Is AI really trying to escape human control and blackmail people?</title><link>https://316140221.github.io/Hugo/zh/en/tech/2025-08-13-is-ai-really-trying-to-escape-human-control-and-bl/</link><pubDate>Wed, 13 Aug 2025 20:28:20 +0800</pubDate><guid>https://316140221.github.io/Hugo/zh/en/tech/2025-08-13-is-ai-really-trying-to-escape-human-control-and-bl/</guid><description>Opinion: Theatrical testing scenarios explain why AI models produce alarming outputs—and why we fall for it.</description></item><item><title>White House unveils sweeping plan to “win” global AI race through deregulation</title><link>https://316140221.github.io/Hugo/zh/en/tech/2025-07-24-white-house-unveils-sweeping-plan-to-win-global-ai/</link><pubDate>Thu, 24 Jul 2025 14:37:05 +0800</pubDate><guid>https://316140221.github.io/Hugo/zh/en/tech/2025-07-24-white-house-unveils-sweeping-plan-to-win-global-ai/</guid><description>Trump&amp;rsquo;s &amp;ldquo;AI Action Plan&amp;rdquo; reverses regulations, sparks critical pushback.</description></item><item><title>AI therapy bots fuel delusions and give dangerous advice, Stanford study finds</title><link>https://316140221.github.io/Hugo/zh/en/tech/2025-07-11-ai-therapy-bots-fuel-delusions-and-give-dangerous-/</link><pubDate>Fri, 11 Jul 2025 22:01:10 +0800</pubDate><guid>https://316140221.github.io/Hugo/zh/en/tech/2025-07-11-ai-therapy-bots-fuel-delusions-and-give-dangerous-/</guid><description>Popular chatbots serve as poor replacements for human therapists, but study authors call for nuance.</description></item></channel></rss>