<!doctype html><html lang=zh-CN><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Anthropic Will Now Train Claude on Your Chats, Here's How to Opt Out - 无关紧要的宇宙</title><meta name=description content="自动化内容聚合网站 - 中文版"><meta name=keywords content="新闻,资讯,聚合,科技,财经,娱乐"><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-XXXXXXXXXX" crossorigin=anonymous></script><style>body{font-family:Arial,sans-serif;margin:0;padding:0}.container{max-width:1200px;margin:0 auto;padding:20px}.header{background:#f8f9fa;padding:1rem}.nav{background:#343a40}.nav ul{list-style:none;margin:0;padding:0;display:flex}.nav li{margin-right:20px}.nav a{color:#fff;text-decoration:none;padding:10px;display:block}.content{margin:20px 0}.sidebar{float:right;width:300px;margin-left:20px;background:#f8f9fa;padding:20px;border-radius:8px}.sidebar h3{margin-top:0;color:#333;border-bottom:2px solid #007bff;padding-bottom:10px}.sidebar .article-item{padding:10px 0;border-bottom:1px solid #ddd}.sidebar .article-item:last-child{border-bottom:none}.sidebar .article-item a{color:#333;text-decoration:none;font-size:14px;display:block;margin-bottom:5px;line-height:1.3}.sidebar .article-item a:hover{color:#007bff}.sidebar .article-meta{font-size:12px;color:#888}.main{overflow:hidden}.ad-banner{text-align:center;margin:20px 0}.article-list{}.article-item{border-bottom:1px solid #eee;padding:15px 0;transition:background-color .2s}.article-item:hover{background-color:#f8f9fa}.article-title{font-size:18px;margin-bottom:5px;line-height:1.4}.article-title a{color:#333;text-decoration:none}.article-title a:hover{color:#007bff}.article-meta{color:#666;font-size:14px;margin-bottom:8px}.article-summary{margin-top:10px;color:#555;line-height:1.5}.footer{background:#f8f9fa;text-align:center;padding:20px;margin-top:40px}.language-switcher{display:flex;align-items:center;gap:8px}.lang-link{color:#aaa;text-decoration:none;padding:4px 8px;border-radius:4px;transition:background-color .2s}.lang-link:hover{background-color:#495057;color:#fff}.current-lang{color:#fff;font-weight:700;padding:4px 8px;background-color:#007bff;border-radius:4px}</style></head><body><header class=header><div class=container><h1>无关紧要的宇宙</h1></div></header><nav class=nav><div class=container><ul style=display:flex;align-items:center><li><a href=https://316140221.github.io/Hugo/>首页</a></li><li><a href=https://316140221.github.io/Hugo/tech/>科技</a></li><li><a href=https://316140221.github.io/Hugo/finance/>财经</a></li><li><a href=https://316140221.github.io/Hugo/entertainment/>娱乐</a></li><li style=margin-left:auto><div class=language-switcher><span class=current-lang>中文</span>
<a href=https://316140221.github.io/Hugo//en/ class=lang-link hreflang=en>English</a></div></li></ul></div></nav><div class=container><div class=ad-banner><ins class=adsbygoogle style=display:block data-ad-client=ca-pub-XXXXXXXXXX data-ad-slot=XXXXXXXXXX data-ad-format=auto data-full-width-responsive=true></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div></div><div class=container><div class=content><article><h1>Anthropic Will Now Train Claude on Your Chats, Here's How to Opt Out</h1><div class=article-meta>发布时间: 2025-08-28 17:46 |
分类: <a href=/categories/tech>tech</a> |
标签: <a href=/tags/anthropic>Anthropic</a></div><div class=ad-banner><ins class=adsbygoogle style=display:block;text-align:center data-ad-layout=in-article data-ad-format=fluid data-ad-client=ca-pub-XXXXXXXXXX data-ad-slot=XXXXXXXXXX></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div><div class=article-content><p>Anthropic announced today that it is changing its Consumer Terms and Privacy Policy, with plans to train its AI chatbot Claude with user data. New users will be able to opt out at signup. Existing users will receive a popup that allows them to opt out of Anthropic using their data for AI training purposes. The popup is labeled &ldquo;Updates to Consumer Terms and Policies,&rdquo; and when it shows up, unchecking the &ldquo;You can help improve Claude&rdquo; toggle will disallow the use of chats. Choosing to accept the policy now will allow all new or resumed chats to be used by Anthropic. Users will need to opt in or opt out by September 28, 2025, to continue using Claude. Opting out can also be done by going to Claude&rsquo;s Settings, selecting the Privacy option, and toggling off &ldquo;Help improve Claude.&rdquo; Anthropic says that the new training policy will allow it to deliver &ldquo;even more capable, useful AI models&rdquo; and strengthen safeguards against harmful usage like scams and abuse. The updated terms apply to all users&mldr;</p><hr><p><em>来源: <a href=https://www.macrumors.com/2025/08/28/anthropic-claude-chat-training/>原文链接</a></em></p></div><div class=ad-banner><ins class=adsbygoogle style=display:block data-ad-client=ca-pub-XXXXXXXXXX data-ad-slot=XXXXXXXXXX data-ad-format=auto data-full-width-responsive=true></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div><div style="margin-top:20px;padding:10px;background:#f8f9fa;border-left:4px solid #007bff"><p><strong>原文链接:</strong> <a href=https://www.macrumors.com/2025/08/28/anthropic-claude-chat-training/ target=_blank>https://www.macrumors.com/2025/08/28/anthropic-claude-chat-training/</a></p></div></article><div style=margin-top:40px><h3>相关文章</h3><div class=article-item><a href=https://316140221.github.io/Hugo/zh/zh/tech/2025-08-28-anthropic-will-now-train-claude-on-your-chats-here/>Anthropic Will Now Train Claude on Your Chats, Here's How to Opt Out</a><div class=article-meta>08-28</div></div><div class=article-item><a href=https://316140221.github.io/Hugo/zh/en/tech/2025-08-28-anthropic-will-start-training-its-ai-models-on-cha/>Anthropic will start training its AI models on chat transcripts</a><div class=article-meta>08-28</div></div><div class=article-item><a href=https://316140221.github.io/Hugo/zh/zh/tech/2025-08-28-anthropic-will-start-training-its-ai-models-on-cha/>Anthropic will start training its AI models on chat transcripts</a><div class=article-meta>08-28</div></div><div class=article-item><a href=https://316140221.github.io/Hugo/zh/en/tech/2025-08-28-the-personhood-trap-how-ai-fakes-human-personality/>The personhood trap: How AI fakes human personality</a><div class=article-meta>08-28</div></div><div class=article-item><a href=https://316140221.github.io/Hugo/zh/en/tech/2025-08-27-anthropics-auto-clicking-ai-chrome-extension-raise/>Anthropic’s auto-clicking AI Chrome extension raises browser-hijacking concerns</a><div class=article-meta>08-27</div></div></div></div></div><footer class=footer><div class=container><p>&copy; 2025 无关紧要的宇宙. All rights reserved.</p></div></footer></body></html>