<!doctype html><html lang=zh-CN><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>AI therapy bots fuel delusions and give dangerous advice, Stanford study finds - 无关紧要的宇宙</title><meta name=description content="自动化内容聚合网站 - 中文版"><meta name=keywords content="新闻,资讯,聚合,科技,财经,娱乐"><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-XXXXXXXXXX" crossorigin=anonymous></script><style>body{font-family:Arial,sans-serif;margin:0;padding:0}.container{max-width:1200px;margin:0 auto;padding:20px}.header{background:#f8f9fa;padding:1rem}.nav{background:#343a40}.nav ul{list-style:none;margin:0;padding:0;display:flex}.nav li{margin-right:20px}.nav a{color:#fff;text-decoration:none;padding:10px;display:block}.content{margin:20px 0}.sidebar{float:right;width:300px;margin-left:20px}.main{overflow:hidden}.ad-banner{text-align:center;margin:20px 0}.article-list{}.article-item{border-bottom:1px solid #eee;padding:15px 0}.article-title{font-size:18px;margin-bottom:5px}.article-meta{color:#666;font-size:14px}.article-summary{margin-top:10px}.footer{background:#f8f9fa;text-align:center;padding:20px;margin-top:40px}.language-switcher{display:flex;align-items:center;gap:8px}.lang-link{color:#aaa;text-decoration:none;padding:4px 8px;border-radius:4px;transition:background-color .2s}.lang-link:hover{background-color:#495057;color:#fff}.current-lang{color:#fff;font-weight:700;padding:4px 8px;background-color:#007bff;border-radius:4px}</style></head><body><header class=header><div class=container><h1>无关紧要的宇宙</h1></div></header><nav class=nav><div class=container><ul style=display:flex;align-items:center><li><a href=https://316140221.github.io/Hugo/>首页</a></li><li><a href=https://316140221.github.io/Hugo/tech/>科技</a></li><li><a href=https://316140221.github.io/Hugo/finance/>财经</a></li><li><a href=https://316140221.github.io/Hugo/entertainment/>娱乐</a></li><li style=margin-left:auto><div class=language-switcher><span class=current-lang>中文</span>
<a href=https://316140221.github.io/Hugo//en/ class=lang-link hreflang=en>English</a></div></li></ul></div></nav><div class=container><div class=ad-banner><ins class=adsbygoogle style=display:block data-ad-client=ca-pub-XXXXXXXXXX data-ad-slot=XXXXXXXXXX data-ad-format=auto data-full-width-responsive=true></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div></div><div class=container><div class=content><article><h1>AI therapy bots fuel delusions and give dangerous advice, Stanford study finds</h1><div class=article-meta>发布时间: 2025-07-11 22:01 |
分类: <a href=/categories/tech>tech</a> |
标签: <a href=/tags/ai>AI</a> <a href=/tags/biz-it>Biz & IT</a> <a href=/tags/science>Science</a> <a href=/tags/7cups>7cups</a> <a href=/tags/ai-behavior>AI behavior</a> <a href=/tags/ai-ethics>AI ethics</a> <a href=/tags/ai-regulation>AI regulation</a> <a href=/tags/ai-safety>AI safety</a> <a href=/tags/ai-sycophancy>AI sycophancy</a> <a href=/tags/character.ai>Character.AI</a> <a href=/tags/chatgpt>ChatGPT</a> <a href=/tags/clinical-psychology>clinical psychology</a> <a href=/tags/delusions>delusions</a> <a href=/tags/jared-moore>Jared Moore</a> <a href=/tags/machine-learning>machine learning</a> <a href=/tags/mental-health>mental health</a> <a href=/tags/nick-haber>Nick Haber</a> <a href=/tags/openai>openai</a> <a href=/tags/stanford-university>Stanford University</a> <a href=/tags/stigma>stigma</a> <a href=/tags/suicidal-ideation>suicidal ideation</a> <a href=/tags/therapy>therapy</a></div><div class=ad-banner><ins class=adsbygoogle style=display:block;text-align:center data-ad-layout=in-article data-ad-format=fluid data-ad-client=ca-pub-XXXXXXXXXX data-ad-slot=XXXXXXXXXX></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div><div class=article-content><p>Popular chatbots serve as poor replacements for human therapists, but study authors call for nuance.</p><hr><p><em>来源: <a href=https://arstechnica.com/ai/2025/07/ai-therapy-bots-fuel-delusions-and-give-dangerous-advice-stanford-study-finds/>原文链接</a></em></p></div><div class=ad-banner><ins class=adsbygoogle style=display:block data-ad-client=ca-pub-XXXXXXXXXX data-ad-slot=XXXXXXXXXX data-ad-format=auto data-full-width-responsive=true></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div><div style="margin-top:20px;padding:10px;background:#f8f9fa;border-left:4px solid #007bff"><p><strong>原文链接:</strong> <a href=https://arstechnica.com/ai/2025/07/ai-therapy-bots-fuel-delusions-and-give-dangerous-advice-stanford-study-finds/ target=_blank>https://arstechnica.com/ai/2025/07/ai-therapy-bots-fuel-delusions-and-give-dangerous-advice-stanford-study-finds/</a></p></div></article><div style=margin-top:40px><h3>相关文章</h3><div class=article-item><a href=https://316140221.github.io/Hugo/zh/en/tech/2025-07-10-cops-favorite-ai-tool-automatically-deletes-eviden/>Cops’ favorite AI tool automatically deletes evidence of when AI was used</a><div class=article-meta>07-10</div></div><div class=article-item><a href=https://316140221.github.io/Hugo/zh/en/tech/2025-07-11-openais-windsurf-deal-is-off-and-windsurfs-ceo-is-/>OpenAI’s Windsurf deal is off — and Windsurf’s CEO is going to Google</a><div class=article-meta>07-11</div></div><div class=article-item><a href=https://316140221.github.io/Hugo/zh/zh/tech/2025-07-11-openais-windsurf-deal-is-off-and-windsurfs-ceo-is-/>OpenAI’s Windsurf deal is off — and Windsurf’s CEO is going to Google</a><div class=article-meta>07-11</div></div><div class=article-item><a href=https://316140221.github.io/Hugo/zh/en/tech/2025-07-11-the-unholy-alliance-that-killed-the-ai-moratorium/>The unholy alliance that killed the AI moratorium</a><div class=article-meta>07-11</div></div><div class=article-item><a href=https://316140221.github.io/Hugo/zh/zh/tech/2025-07-11-the-unholy-alliance-that-killed-the-ai-moratorium/>The unholy alliance that killed the AI moratorium</a><div class=article-meta>07-11</div></div></div></div></div><footer class=footer><div class=container><p>&copy; 2025 无关紧要的宇宙. All rights reserved.</p></div></footer></body></html>